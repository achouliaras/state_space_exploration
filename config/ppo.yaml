agent:
  #_target_: agent.ppo.PPOAgent
  obs_shape: Null # to be specified on execution
  obs_dim: Null # to be specified on execution
  action_dim: Null # to be specified on execution
  action_range: Null # to be specified on execution
  # device: ${device}
  critic_cfg: Null # to be specified on execution
  actor_cfg: Null # to be specified on execution
  action_cfg: Null # to be specified on execution
  
discrete_action:
  num_update_steps: 128
  batch_size: Null
  lr: 3e-4
  anneal_lr: True
  discount: 0.99
  gae_lambda: 0.95
  num_minibatches: 4
  update_epochs: 4
  norm_adv: True
  clip_coef: 0.1
  clip_vloss: True
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: None

continuous_action:
  num_update_steps: 128
  batch_size: Null
  lr: 3e-4
  anneal_lr: True
  discount: 0.99
  gae_lambda: 0.95
  num_minibatches: 4
  update_epochs: 4
  norm_adv: True
  clip_coef: 0.2
  clip_vloss: True
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: None

double_q_critic:
  #_target_: agent.critic.DoubleQCritic
  obs_dim: ${agent.obs_dim}
  action_dim: ${agent.action_dim}
  action_type: 'Discrete'
  state_type: 'tabular'
  architecture: 'MLP'
  hidden_dim: 512
  hidden_depth: 1

categorical_actor:
  #_target_: agent.actor.CategoricalActor
  obs_dim: ${agent.obs_dim}
  action_dim: ${agent.action_dim}
  action_type: 'Discrete'
  architecture: 'CNN'
  hidden_depth: 1
  hidden_dim: 512
