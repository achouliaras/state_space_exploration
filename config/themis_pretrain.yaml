defaults:
    - _self_
    - sac
    
# this needs to be specified manually
experiment: THEMIS

# unsup training
gradient_update: 1
num_unsup_steps: 0 #5000
topK: 5

# reward learning
learn_reward: True
segment: 50
activation: tanh
num_seed_steps: 5000 # Steps that the agent does random actions to fill the buffers
num_interact: 4000 # After how many steps we retrain the reward model
reward_lr: 0.003
reward_batch: 50 # How many segments will be generated for human input
reward_update: 200 # How many epochs the reward model is training for
feed_type: 0 # the sampling method used
ensemble_size: 3
max_feedback: 1400 # Max total number of interactions (incremented by reward_batch)
large_batch: 10
label_margin: 0.0
reward_scale: 1.0
reward_intercept: 0.0
human_teacher: False # Use human input on True, uses synthetic feedback on False
teacher_beta: -1    # Rationality Constant 0 leads to random choices and infinite (-1) to perfectly rational
teacher_gamma: 1    # Discound Factor for myopic behavior paying more attention on recent states
teacher_eps_mistake: 0  # Probability of mistake
teacher_eps_skip: 0     # Probability of considering both segments bad
teacher_eps_equal: 0    # Probability of considering both segments equally good

# scheduling
reward_schedule: 0

num_train_steps: 1000000
replay_buffer_capacity: 10000
reward_model_capacity: 10000

# evaluation config
eval_frequency: 100 #10000
num_eval_episodes: 10
device: cpu

# logger
log_frequency: 10
log_save_tb: true

# video recorder
save_video: true
video_location: Null
record_frequency: 10

# setups
seed: 1
debug: False

# Environment
domain: Box2D
env: LunarLander-v3
render_mode: None
#max_episode_steps: 100

action_type: Null
state_type: Null
architecture: MLP
mode: 0
action_space: Null
obs_space: Null
action_dim: Null

#Atari Settings (some for Box2D CarRacing)
obs_type: rgb # [rgb, ram, greyscale]
frame_stack: 4 # only works if obs_type=pixels
frameskip: 4
action_repeat: 1 # set to 2 for pixels
noop_max: 30
grayscale_obs: True
scale_obs: False

#Xplain Params
checkpoint_frec: 500 # No. of steps to 
checkpoints_dir: checkpoints/${obs_type}/${env}/sac/
xplain_action: False
xplain_state: False

# Snapshot
#snapshots: [100000, 500000, 1000000, 2000000]
snapshot_dir: models/${obs_type}/${env}/sac/
