agent:
  #_target_: agent.sac.SACAgent
  obs_shape: Null # to be specified on execution
  obs_dim: Null # to be specified on execution
  action_dim: Null # to be specified on execution
  action_range: Null # to be specified on execution
  # device: ${device}
  critic_cfg: Null # to be specified on execution
  actor_cfg: Null # to be specified on execution
  action_cfg: Null # to be specified on execution
  discount: 0.99
  init_temperature: 0.1
  critic_target_update_frequency: 8000 # steps
  learnable_temperature: True
  
discrete_action:
  actor_update_frequency: 4
  batch_size: 64
  alpha_lr: 3e-4
  actor_lr: 3e-4
  critic_lr: 3e-3
  critic_update_frequency: 4
  critic_target_update_frequency: 8000 # steps
  target_entropy_scale: 0.89
  critic_tau: 1 # target critic percentage change from critic

continuous_action:
  actor_update_frequency: 2
  batch_size: 256
  alpha_lr: 3e-3
  actor_lr: 3e-4
  critic_lr: 3e-3
  critic_update_frequency: 1
  critic_target_update_frequency: 1 # steps
  target_entropy_scale: 1
  critic_tau: 0.005 # target critic percentage change from critic

double_q_critic:
  #_target_: agent.critic.DoubleQCritic
  obs_dim: ${agent.obs_dim}
  action_dim: ${agent.action_dim}
  action_type: 'Discrete'
  state_type: 'tabular'
  architecture: 'MLP'
  hidden_dim: 512
  hidden_depth: 1
    
diag_gaussian_actor:
  #_target_: agent.actor.DiagGaussianActor
  obs_dim: ${agent.obs_dim}
  action_dim: ${agent.action_dim}
  action_type: 'Continuous'
  architecture: 'MLP'
  hidden_depth: 2
  hidden_dim: 512
  log_std_bounds: [-5, 2]

categorical_actor:
  #_target_: agent.actor.CategoricalActor
  obs_dim: ${agent.obs_dim}
  action_dim: ${agent.action_dim}
  action_type: 'Discrete'
  architecture: 'CNN'
  hidden_depth: 1
  hidden_dim: 512
